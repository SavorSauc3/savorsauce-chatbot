{
  "Meta-Llama-3-8B-Instruct-abliterated-v3_q6.gguf": {
    "general.name": "Meta-Llama-3-8B-Instruct-abliterated-v3",
    "general.architecture": "llama",
    "llama.block_count": 32,
    "llama.context_length": 8192,
    "tokenizer.ggml.eos_token_id": 128009,
    "general.file_type": 18,
    "llama.attention.head_count_kv": 8,
    "llama.embedding_length": 4096,
    "llama.feed_forward_length": 14336,
    "llama.attention.head_count": 32,
    "llama.rope.freq_base": "500000.000000",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.vocab_size": 128256,
    "llama.rope.dimension_count": 128,
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
    "general.quantization_version": 2,
    "tokenizer.ggml.bos_token_id": 128000,
    "tokenizer.chat_template": "{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\n\n' }}{% endif %}"
  },
  "Codestral-22B-v0.1-Q5_K_M.gguf": {
    "general.name": "Codestral-22B-v0.1",
    "general.architecture": "llama",
    "llama.block_count": 56,
    "llama.context_length": 32768,
    "tokenizer.ggml.eos_token_id": 2,
    "general.file_type": 17,
    "llama.attention.head_count_kv": 8,
    "llama.embedding_length": 6144,
    "llama.feed_forward_length": 16384,
    "llama.attention.head_count": 48,
    "llama.rope.freq_base": "1000000.000000",
    "quantize.imatrix.entries_count": 392,
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.vocab_size": 32768,
    "llama.rope.dimension_count": 128,
    "tokenizer.ggml.model": "llama",
    "tokenizer.ggml.pre": "default",
    "general.quantization_version": 2,
    "tokenizer.ggml.bos_token_id": 1,
    "tokenizer.ggml.add_bos_token": "true",
    "tokenizer.ggml.add_eos_token": "false",
    "quantize.imatrix.chunks_count": 148,
    "quantize.imatrix.file": "/models/Codestral-22B-v0.1-GGUF/Codestral-22B-v0.1.imatrix",
    "quantize.imatrix.dataset": "/training_data/calibration_datav3.txt"
  }
}